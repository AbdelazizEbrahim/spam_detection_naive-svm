{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f76d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    RocCurveDisplay,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65efd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_time(message, start_time):\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{message} took {elapsed:.4f} seconds\")\n",
    "    return elapsed\n",
    "\n",
    "def preview_file(file_path, num_lines=5):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            print(f\"Previewing first {num_lines} lines of {file_path}:\")\n",
    "            for i, line in enumerate(f, 1):\n",
    "                if i > num_lines:\n",
    "                    break\n",
    "                print(f\"Line {i}: {line.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing file: {e}\")\n",
    "\n",
    "def clean_dataset(file_path, output_path='data/cleaned_dataset.csv'):\n",
    "    print(f\"Cleaning dataset: {file_path}\")\n",
    "    start = time.time()\n",
    "    cleaned_lines = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                line = re.sub(r'\\t+', '\\t', line)\n",
    "                line = line.replace('\"', '')\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    label, text = parts[0], ' '.join(parts[1:])\n",
    "                    cleaned_lines.append(f\"{label}\\t{text}\")\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line.strip()}\")\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(cleaned_lines))\n",
    "        print(f\"Cleaned dataset saved to {output_path}\")\n",
    "        log_time(\"Dataset cleaning\", start)\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning dataset: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6af8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path='data/dataset.csv'):\n",
    "    start = time.time()\n",
    "    preview_file(file_path)\n",
    "    cleaned_file_path = clean_dataset(file_path)\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            cleaned_file_path,\n",
    "            sep='\\t',\n",
    "            header=None,\n",
    "            names=['label', 'text'],\n",
    "            engine='python',\n",
    "            encoding='utf-8',\n",
    "            quoting=3\n",
    "        )\n",
    "        df['label'] = df['label'].map({'ham': 'not_spam', 'spam': 'spam'})\n",
    "        df = df.dropna(subset=['label', 'text'])\n",
    "        df = df[df['label'].isin(['not_spam', 'spam'])]\n",
    "        print(f\"Loaded {len(df)} valid samples\")\n",
    "        print(f\"Class distribution: {df['label'].value_counts().to_dict()}\")\n",
    "        log_time(\"Data loading and preprocessing\", start)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da65fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(X_train, X_test):\n",
    "    start = time.time()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=20000,\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=2\n",
    "    )\n",
    "    X_train_vect = vectorizer.fit_transform(X_train).astype(np.float32)\n",
    "    X_test_vect = vectorizer.transform(X_test).astype(np.float32)\n",
    "    print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "    log_time(\"Text vectorization\", start)\n",
    "    return vectorizer, X_train_vect, X_test_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf05249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X_train, y_train):\n",
    "    start = time.time()\n",
    "    model = MultinomialNB(alpha=0.5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Naïve Bayes model trained successfully\")\n",
    "    log_time(\"Naïve Bayes training\", start)\n",
    "    return model\n",
    "\n",
    "def train_svm(X_train, y_train):\n",
    "    start = time.time()\n",
    "    model = LinearSVC(C=1.0, max_iter=1000, dual=False, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"SVM model trained successfully\")\n",
    "    log_time(\"SVM training\", start)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dafc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, X_test, y_test):\n",
    "    start = time.time()\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, preds, labels=['not_spam', 'spam'])\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=['Actual: not_spam', 'Actual: spam'],\n",
    "        columns=['Predicted: not_spam', 'Predicted: spam']\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (spam): {report['spam']['precision']:.4f}\")\n",
    "    print(f\"Recall (spam): {report['spam']['recall']:.4f}\")\n",
    "    print(f\"F1-score (spam): {report['spam']['f1-score']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    display(cm_df)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not_spam', 'spam'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_score = model.decision_function(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test.map({'not_spam': 0, 'spam': 1}), y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    log_time(f\"{model_name} evaluation\", start)\n",
    "    return preds, accuracy, report, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d2d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(nb_accuracy, svm_accuracy, nb_report, svm_report, nb_cm, svm_cm):\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(f\"Naïve Bayes Accuracy: {nb_accuracy:.4f}\")\n",
    "    print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "    print(f\"Accuracy Difference (SVM - NB): {svm_accuracy - nb_accuracy:.4f}\")\n",
    "    print(\"\\nSpam Class Metrics Comparison:\")\n",
    "    print(f\"{'Metric':<15} {'Naïve Bayes':<15} {'SVM':<15}\")\n",
    "    print(f\"{'-'*45}\")\n",
    "    print(f\"{'Precision':<15} {nb_report['spam']['precision']:<15.4f} {svm_report['spam']['precision']:<15.4f}\")\n",
    "    print(f\"{'Recall':<15} {nb_report['spam']['recall']:<15.4f} {svm_report['spam']['recall']:<15.4f}\")\n",
    "    print(f\"{'F1-score':<15} {nb_report['spam']['f1-score']:<15.4f} {svm_report['spam']['f1-score']:<15.4f}\")\n",
    "    \n",
    "    # Display confusion matrices\n",
    "    nb_cm_df = pd.DataFrame(\n",
    "        nb_cm,\n",
    "        index=['Actual: not_spam', 'Actual: spam'],\n",
    "        columns=['Predicted: not_spam', 'Predicted: spam']\n",
    "    )\n",
    "    svm_cm_df = pd.DataFrame(\n",
    "        svm_cm,\n",
    "        index=['Actual: not_spam', 'Actual: spam'],\n",
    "        columns=['Predicted: not_spam', 'Predicted: spam']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nNaïve Bayes Confusion Matrix:\")\n",
    "    display(nb_cm_df)\n",
    "    print(\"\\nSVM Confusion Matrix:\")\n",
    "    display(svm_cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fdaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_text(model, model_name, vectorizer, text):\n",
    "    start = time.time()\n",
    "    text_vect = vectorizer.transform([text]).astype(np.float32)\n",
    "    pred = model.predict(text_vect)[0]\n",
    "    elapsed = log_time(f\"{model_name} single text prediction\", start)\n",
    "    return pred, elapsed\n",
    "\n",
    "def explain_prediction(model, model_name, vectorizer, text):\n",
    "    start = time.time()\n",
    "    text_vect = vectorizer.transform([text]).toarray()[0]\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    if model_name == \"Naïve Bayes\":\n",
    "        spam_probs = np.exp(model.feature_log_prob_[1])\n",
    "        top_features = sorted(\n",
    "            [(feature_names[i], spam_probs[i]) for i in np.where(text_vect > 0)[0]],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:5]\n",
    "    else:  # SVM\n",
    "        weights = model.coef_[0]\n",
    "        top_features = sorted(\n",
    "            [(feature_names[i], weights[i]) for i in np.where(text_vect > 0)[0]],\n",
    "            key=lambda x: abs(x[1]),\n",
    "            reverse=True\n",
    "        )[:5]\n",
    "    \n",
    "    elapsed = log_time(f\"{model_name} prediction explanation\", start)\n",
    "    return top_features, elapsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
